{
  "cards": [
    {
      "id": 1,
      "category": "Data Engineering Concepts",
      "question": "What's the key difference between ETL and ELT?",
      "answer": "ETL (Extract-Transform-Load): Transforms data before loading into the destination. Transformation happens in a staging area. Good for legacy systems with limited compute.\n\nELT (Extract-Load-Transform): Loads raw data first, then transforms in the destination warehouse. Leverages modern warehouse compute power (like Snowflake, BigQuery). Better for big data and flexibility.",
      "difficulty": "medium",
      "tags": ["architecture", "data-pipeline", "etl"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 2,
      "category": "Data Engineering Concepts",
      "question": "What is data idempotency and why is it important?",
      "answer": "Idempotency means that running the same operation multiple times produces the same result as running it once.\n\nImportance:\n- Enables safe retries after failures\n- Prevents duplicate data in pipelines\n- Critical for data quality and consistency\n\nExample: INSERT INTO with WHERE NOT EXISTS, or using MERGE/UPSERT instead of plain INSERT.",
      "difficulty": "medium",
      "tags": ["data-quality", "best-practices"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 3,
      "category": "Data Engineering Concepts",
      "question": "What is the CAP theorem?",
      "answer": "CAP theorem states that a distributed system can only guarantee 2 out of 3:\n\nC - Consistency: All nodes see the same data at the same time\nA - Availability: System remains operational and responds to requests\nP - Partition Tolerance: System continues despite network failures\n\nIn practice, partition tolerance is required, so you choose between:\n- CP systems: Consistency over availability (e.g., HBase, MongoDB)\n- AP systems: Availability over consistency (e.g., Cassandra, DynamoDB)",
      "difficulty": "hard",
      "tags": ["distributed-systems", "theory"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 4,
      "category": "Data Engineering Concepts",
      "question": "Explain Data Lake vs Data Warehouse",
      "answer": "Data Lake:\n- Stores raw, unprocessed data in native format\n- Schema-on-read (define schema when reading)\n- Cheap storage (e.g., S3, HDFS)\n- Good for exploratory analysis, ML\n- Example: AWS S3, Azure Data Lake\n\nData Warehouse:\n- Stores processed, structured data\n- Schema-on-write (define schema when writing)\n- Optimized for fast queries\n- Good for BI and reporting\n- Example: Snowflake, BigQuery, Redshift",
      "difficulty": "easy",
      "tags": ["architecture", "storage"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 5,
      "category": "Data Engineering Concepts",
      "question": "What is a Slowly Changing Dimension (SCD) Type 2?",
      "answer": "SCD Type 2 tracks historical changes by creating new rows for each change.\n\nColumns typically include:\n- Surrogate key (unique for each version)\n- Natural/business key\n- Effective_from date\n- Effective_to date (or NULL for current)\n- is_current flag\n\nExample:\nCustomer_ID | Name | Address | Effective_From | Effective_To | is_current\n1 | Alice | NYC | 2020-01-01 | 2022-05-01 | false\n2 | Alice | SF | 2022-05-01 | NULL | true\n\nBenefit: Full history preserved for analysis.",
      "difficulty": "medium",
      "tags": ["dimensional-modeling", "data-warehouse"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 6,
      "category": "SQL Concepts",
      "question": "What's the difference between UNION and UNION ALL?",
      "answer": "UNION:\n- Combines result sets and removes duplicates\n- Performs implicit DISTINCT (slower)\n- Requires sorting to find duplicates\n\nUNION ALL:\n- Combines result sets and keeps all rows (including duplicates)\n- Faster (no deduplication overhead)\n- Preserves all data\n\nRule of thumb: Use UNION ALL when you know there are no duplicates or want to keep them. It's more performant.",
      "difficulty": "easy",
      "tags": ["sql", "performance"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 7,
      "category": "SQL Concepts",
      "question": "When would you use a window function vs GROUP BY?",
      "answer": "GROUP BY:\n- Aggregates rows into groups\n- Reduces number of rows in output\n- Can't access individual row details after aggregation\n- Example: Total sales per region\n\nWindow Functions:\n- Performs calculation across rows while keeping all rows\n- Doesn't reduce row count\n- Can see both detail and aggregate\n- Example: Running total, ranking, moving average\n\nUse window function when you need both detail-level and aggregate data in the same query.",
      "difficulty": "medium",
      "tags": ["sql", "window-functions"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 8,
      "category": "SQL Concepts",
      "question": "Explain the difference between WHERE and HAVING",
      "answer": "WHERE:\n- Filters rows BEFORE aggregation\n- Cannot use aggregate functions\n- Applied to individual rows\n- Example: WHERE age > 25\n\nHAVING:\n- Filters groups AFTER aggregation\n- Can use aggregate functions\n- Applied to grouped results\n- Example: HAVING COUNT(*) > 5\n\nExecution order: FROM → WHERE → GROUP BY → HAVING → SELECT → ORDER BY",
      "difficulty": "easy",
      "tags": ["sql", "fundamentals"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 9,
      "category": "Python/Pandas",
      "question": "What's the difference between loc and iloc in pandas?",
      "answer": "loc: Label-based indexing\n- Uses row/column labels\n- Inclusive of end point\n- Example: df.loc[0:5] includes rows 0-5\n- Example: df.loc[:, 'name':'age'] includes 'name' and 'age'\n\niloc: Position-based indexing\n- Uses integer positions (0-indexed)\n- Exclusive of end point\n- Example: df.iloc[0:5] includes rows 0-4\n- Example: df.iloc[:, 0:3] includes first 3 columns\n\nRule: Use loc for labels, iloc for positions.",
      "difficulty": "easy",
      "tags": ["pandas", "indexing"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 10,
      "category": "Python/Pandas",
      "question": "Explain merge vs join vs concat in pandas",
      "answer": "merge(): SQL-style joins\n- Combines on columns\n- Flexible: can specify left_on, right_on\n- Example: pd.merge(df1, df2, on='key', how='left')\n\njoin(): Index-based joins\n- Joins on index by default\n- Less flexible than merge\n- Example: df1.join(df2)\n\nconcat(): Stacking DataFrames\n- Concatenates along axis (0=rows, 1=columns)\n- Doesn't match on keys by default\n- Example: pd.concat([df1, df2], axis=0)\n\nMost common: merge() for joins, concat() for stacking.",
      "difficulty": "medium",
      "tags": ["pandas", "joining"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 11,
      "category": "AWS Services",
      "question": "What are the key differences between S3, RDS, and Redshift?",
      "answer": "S3 (Simple Storage Service):\n- Object storage for files\n- Unlimited scalability\n- Cheap (pennies per GB/month)\n- Use for: Data lakes, backups, file storage\n\nRDS (Relational Database Service):\n- Managed relational database (PostgreSQL, MySQL, etc.)\n- OLTP (transactional workloads)\n- Row-based storage\n- Use for: Application databases, transactional data\n\nRedshift:\n- Data warehouse\n- OLAP (analytical workloads)\n- Columnar storage\n- Optimized for complex queries on large datasets\n- Use for: Analytics, BI, reporting",
      "difficulty": "easy",
      "tags": ["aws", "storage", "databases"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 12,
      "category": "AWS Services",
      "question": "What is AWS Lambda and when would you use it?",
      "answer": "AWS Lambda: Serverless compute service\n- Run code without managing servers\n- Pay only for compute time used\n- Auto-scales automatically\n- Triggered by events (S3, API Gateway, etc.)\n- Max runtime: 15 minutes\n\nUse cases for data engineering:\n- ETL for small datasets\n- Data validation triggers\n- File processing on S3 upload\n- Real-time data transformations\n- Scheduling simple tasks\n\nNot ideal for:\n- Long-running jobs (>15 min)\n- Heavy compute workloads\n- Jobs requiring persistent state",
      "difficulty": "medium",
      "tags": ["aws", "serverless", "compute"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 13,
      "category": "System Design",
      "question": "What is sharding and when would you use it?",
      "answer": "Sharding: Horizontal partitioning of data across multiple databases\n\nHow it works:\n- Split large dataset into smaller pieces (shards)\n- Each shard is an independent database\n- Use shard key to determine which shard holds the data\n\nBenefits:\n- Distributes load across multiple machines\n- Improves read/write performance\n- Enables horizontal scaling\n\nChallenges:\n- Complex queries across shards\n- Rebalancing when adding shards\n- Choosing the right shard key\n\nExample: User data sharded by user_id % num_shards",
      "difficulty": "hard",
      "tags": ["system-design", "scalability", "databases"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 14,
      "category": "System Design",
      "question": "Explain the purpose of a message queue (e.g., Kafka, RabbitMQ)",
      "answer": "Message Queue: Middleware for asynchronous communication between services\n\nKey concepts:\n- Producer: Sends messages\n- Consumer: Receives messages\n- Queue/Topic: Holds messages\n- Decouples services\n\nBenefits:\n- Asynchronous processing\n- Load leveling (smooth traffic spikes)\n- Fault tolerance (retry failed messages)\n- Scalability (multiple consumers)\n\nUse cases in data engineering:\n- Event streaming (Kafka)\n- Job queues for ETL\n- Real-time data pipelines\n- Microservices communication\n\nExample: Click events → Kafka → Stream processor → Data warehouse",
      "difficulty": "medium",
      "tags": ["system-design", "messaging", "streaming"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    },
    {
      "id": 15,
      "category": "System Design",
      "question": "What is the difference between batch processing and stream processing?",
      "answer": "Batch Processing:\n- Processes data in large groups at scheduled intervals\n- High latency (hours to days)\n- High throughput\n- Complete data available\n- Tools: Spark, Hadoop MapReduce\n- Example: Daily sales reports\n\nStream Processing:\n- Processes data continuously as it arrives\n- Low latency (seconds to minutes)\n- Lower throughput per message\n- Partial/windowed data\n- Tools: Kafka Streams, Flink, Spark Streaming\n- Example: Real-time fraud detection\n\nChoice depends on:\n- Latency requirements\n- Data velocity\n- Use case (analytics vs real-time decisions)",
      "difficulty": "easy",
      "tags": ["system-design", "data-processing"],
      "last_reviewed": null,
      "next_review": null,
      "confidence": 0,
      "ease_factor": 2.5,
      "interval": 0,
      "repetitions": 0
    }
  ],
  "metadata": {
    "version": "1.0",
    "created": "2026-02-12",
    "total_cards": 15,
    "categories": [
      "Data Engineering Concepts",
      "SQL Concepts",
      "Python/Pandas",
      "AWS Services",
      "System Design"
    ]
  }
}
